{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "jzoDITNIUlHR",
        "outputId": "aca988bf-2f9e-456c-f900-ba52d83b9198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drugsComTrain_raw.csv와 drugsComTest_raw.csv 파일을 업로드하세요.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-18a428df-ad70-43da-a2f5-1bf44bb51c9f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-18a428df-ad70-43da-a2f5-1bf44bb51c9f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving drugsComTest_raw.csv to drugsComTest_raw.csv\n",
            "Saving drugsComTrain_raw.csv to drugsComTrain_raw.csv\n",
            "\n",
            "=== Train 데이터 미리 보기 ===\n",
            "   uniqueID                  drugName                     condition  \\\n",
            "0    206461                 Valsartan  Left Ventricular Dysfunction   \n",
            "1     95260                Guanfacine                          ADHD   \n",
            "2     92703                    Lybrel                 Birth Control   \n",
            "3    138000                Ortho Evra                 Birth Control   \n",
            "4     35696  Buprenorphine / naloxone             Opiate Dependence   \n",
            "\n",
            "                                              review  rating       date  \\\n",
            "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
            "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
            "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
            "3  \"This is my first time using any form of birth...       8   3-Nov-15   \n",
            "4  \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
            "\n",
            "   usefulCount  \n",
            "0           27  \n",
            "1          192  \n",
            "2           17  \n",
            "3           10  \n",
            "4           37  \n",
            "Train 데이터 크기: (161297, 7)\n",
            "\n",
            "=== Test 데이터 미리 보기 ===\n",
            "   uniqueID         drugName                     condition  \\\n",
            "0    163740      Mirtazapine                    Depression   \n",
            "1    206473       Mesalamine  Crohn's Disease, Maintenance   \n",
            "2    159672          Bactrim       Urinary Tract Infection   \n",
            "3     39293         Contrave                   Weight Loss   \n",
            "4     97768  Cyclafem 1 / 35                 Birth Control   \n",
            "\n",
            "                                              review  rating       date  \\\n",
            "0  \"I&#039;ve tried a few antidepressants over th...      10  28-Feb-12   \n",
            "1  \"My son has Crohn&#039;s disease and has done ...       8  17-May-09   \n",
            "2                      \"Quick reduction of symptoms\"       9  29-Sep-17   \n",
            "3  \"Contrave combines drugs that were used for al...       9   5-Mar-17   \n",
            "4  \"I have been on this birth control for one cyc...       9  22-Oct-15   \n",
            "\n",
            "   usefulCount  \n",
            "0           22  \n",
            "1           17  \n",
            "2            3  \n",
            "3           35  \n",
            "4            4  \n",
            "Test 데이터 크기: (53766, 7)\n"
          ]
        }
      ],
      "source": [
        "# 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 파일 업로드 확인\n",
        "print(\"drugsComTrain_raw.csv와 drugsComTest_raw.csv 파일을 업로드하세요.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 파일 이름 설정\n",
        "train_file = \"drugsComTrain_raw.csv\"\n",
        "test_file = \"drugsComTest_raw.csv\"\n",
        "\n",
        "# CSV 파일 읽기\n",
        "train_df = pd.read_csv(train_file)\n",
        "test_df = pd.read_csv(test_file)\n",
        "\n",
        "# 데이터 확인\n",
        "print(\"\\n=== Train 데이터 미리 보기 ===\")\n",
        "print(train_df.head())\n",
        "print(\"Train 데이터 크기:\", train_df.shape)\n",
        "\n",
        "print(\"\\n=== Test 데이터 미리 보기 ===\")\n",
        "print(test_df.head())\n",
        "print(\"Test 데이터 크기:\", test_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 처리\n",
        "train_df = train_df.dropna(subset=['condition', 'review', 'rating'])\n",
        "test_df = test_df.dropna(subset=['condition', 'review', 'rating'])\n",
        "\n",
        "# 중복 제거\n",
        "train_df = train_df.drop_duplicates()\n",
        "test_df = test_df.drop_duplicates()\n",
        "\n",
        "# 텍스트 전처리\n",
        "import re\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # 소문자 변환\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)  # HTML 태그 제거\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # 알파벳과 공백만 남김\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # 불필요한 공백 제거\n",
        "    return text\n",
        "\n",
        "train_df['cleaned_review'] = train_df['review'].apply(clean_text)\n",
        "test_df['cleaned_review'] = test_df['review'].apply(clean_text)\n",
        "\n",
        "# 숫자형 데이터 정리 (Rating)\n",
        "train_df['rating'] = train_df['rating'].astype(float)\n",
        "test_df['rating'] = test_df['rating'].astype(float)\n",
        "\n",
        "# 전처리 결과 확인\n",
        "print(\"\\n=== 전처리된 Train 데이터 ===\")\n",
        "print(train_df[['condition', 'cleaned_review', 'rating']].head())\n",
        "print(\"Train 데이터 크기:\", train_df.shape)\n",
        "\n",
        "print(\"\\n=== 전처리된 Test 데이터 ===\")\n",
        "print(test_df[['condition', 'cleaned_review', 'rating']].head())\n",
        "print(\"Test 데이터 크기:\", test_df.shape)\n",
        "\n",
        "# 파일 저장\n",
        "train_df.to_csv(\"processed_drug_review_train.csv\", index=False)\n",
        "test_df.to_csv(\"processed_drug_review_test.csv\", index=False)\n",
        "print(\"\\n전처리된 데이터가 저장되었습니다: 'processed_drug_review_train.csv', 'processed_drug_review_test.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVt7ibvyUqnE",
        "outputId": "dc987193-d2b9-4958-d3bc-181f09b8fa06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 전처리된 Train 데이터 ===\n",
            "                      condition  \\\n",
            "0  Left Ventricular Dysfunction   \n",
            "1                          ADHD   \n",
            "2                 Birth Control   \n",
            "3                 Birth Control   \n",
            "4             Opiate Dependence   \n",
            "\n",
            "                                      cleaned_review  rating  \n",
            "0  it has no side effect i take it in combination...     9.0  \n",
            "1  my son is halfway through his fourth week of i...     8.0  \n",
            "2  i used to take another oral contraceptive whic...     5.0  \n",
            "3  this is my first time using any form of birth ...     8.0  \n",
            "4  suboxone has completely turned my life around ...     9.0  \n",
            "Train 데이터 크기: (160398, 8)\n",
            "\n",
            "=== 전처리된 Test 데이터 ===\n",
            "                      condition  \\\n",
            "0                    Depression   \n",
            "1  Crohn's Disease, Maintenance   \n",
            "2       Urinary Tract Infection   \n",
            "3                   Weight Loss   \n",
            "4                 Birth Control   \n",
            "\n",
            "                                      cleaned_review  rating  \n",
            "0  ive tried a few antidepressants over the years...    10.0  \n",
            "1  my son has crohns disease and has done very we...     8.0  \n",
            "2                        quick reduction of symptoms     9.0  \n",
            "3  contrave combines drugs that were used for alc...     9.0  \n",
            "4  i have been on this birth control for one cycl...     9.0  \n",
            "Test 데이터 크기: (53471, 8)\n",
            "\n",
            "전처리된 데이터가 저장되었습니다: 'processed_drug_review_train.csv', 'processed_drug_review_test.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 1. 데이터 로드\n",
        "train_df = pd.read_csv(\"processed_drug_review_train.csv\")\n",
        "test_df = pd.read_csv(\"processed_drug_review_test.csv\")\n",
        "\n",
        "# 2. 텍스트 벡터화 (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # 최대 5000개의 특성 생성\n",
        "X = vectorizer.fit_transform(train_df['cleaned_review'])\n",
        "y = train_df['rating']\n",
        "\n",
        "# 3. Train-Test 분할\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. 모델 학습 (Linear Regression)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. 예측 및 평가\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 평가 지표\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(\"\\n=== 회귀 모델 평가 ===\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"R-squared (R²): {r2:.2f}\")\n",
        "\n",
        "# 6. 테스트 데이터 예측\n",
        "X_test = vectorizer.transform(test_df['cleaned_review'])\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# 테스트 데이터 결과 저장\n",
        "test_df['predicted_rating'] = test_predictions\n",
        "test_df.to_csv(\"test_predictions.csv\", index=False)\n",
        "print(\"\\n테스트 데이터 예측 결과가 저장되었습니다: 'test_predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "34bd55AogCzS",
        "outputId": "0a233db7-451b-4d1c-9703-fecf32c3c4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "np.nan is an invalid document, expected byte or unicode string.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ec591a1e84d7>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 2. 텍스트 벡터화 (TF-IDF)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 최대 5000개의 특성 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m         )\n\u001b[0;32m-> 2104\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0;34m\"np.nan is an invalid document, expected byte or unicode string.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 1. 데이터 로드\n",
        "train_df = pd.read_csv(\"processed_drug_review_train.csv\")\n",
        "test_df = pd.read_csv(\"processed_drug_review_test.csv\")\n",
        "\n",
        "# 2. 결측치 확인 및 제거\n",
        "train_df = train_df.dropna(subset=['cleaned_review'])\n",
        "test_df = test_df.dropna(subset=['cleaned_review'])\n",
        "\n",
        "# 3. 텍스트 벡터화 (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # 최대 5000개의 특성 생성\n",
        "X = vectorizer.fit_transform(train_df['cleaned_review'])\n",
        "y = train_df['rating']\n",
        "\n",
        "# 4. Train-Test 분할\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. 모델 학습 (Linear Regression)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 6. 예측 및 평가\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# 평가 지표\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(\"\\n=== 회귀 모델 평가 ===\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"R-squared (R²): {r2:.2f}\")\n",
        "\n",
        "# 7. 테스트 데이터 예측\n",
        "X_test = vectorizer.transform(test_df['cleaned_review'])\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# 테스트 데이터 결과 저장\n",
        "test_df['predicted_rating'] = test_predictions\n",
        "test_df.to_csv(\"test_predictions.csv\", index=False)\n",
        "print(\"\\n테스트 데이터 예측 결과가 저장되었습니다: 'test_predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ53PCQ4j1_p",
        "outputId": "eae7887a-18a8-4a59-a6db-81aff722e38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 회귀 모델 평가 ===\n",
            "Mean Squared Error (MSE): 5.60\n",
            "R-squared (R²): 0.47\n",
            "\n",
            "테스트 데이터 예측 결과가 저장되었습니다: 'test_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Random Forest Regressor 모델 학습\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_rf_pred = rf_model.predict(X_val)\n",
        "\n",
        "# 평가 지표\n",
        "mse_rf = mean_squared_error(y_val, y_rf_pred)\n",
        "r2_rf = r2_score(y_val, y_rf_pred)\n",
        "\n",
        "print(\"\\n=== Random Forest 회귀 모델 평가 ===\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_rf:.2f}\")\n",
        "print(f\"R-squared (R²): {r2_rf:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJHNKoeImyZZ",
        "outputId": "539ed53d-a13e-4abf-aac9-54e46fefc43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Random Forest 회귀 모델 평가 ===\n",
            "Mean Squared Error (MSE): 8.62\n",
            "R-squared (R²): 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Gradient Boosting Regressor 모델 학습\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_gb_pred = gb_model.predict(X_val)\n",
        "\n",
        "# 평가 지표\n",
        "mse_gb = mean_squared_error(y_val, y_gb_pred)\n",
        "r2_gb = r2_score(y_val, y_gb_pred)\n",
        "\n",
        "print(\"\\n=== Gradient Boosting 회귀 모델 평가 ===\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_gb:.2f}\")\n",
        "print(f\"R-squared (R²): {r2_gb:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXzMH1eLoqJ5",
        "outputId": "85a43065-0d2b-4a8f-9379-5558894f0f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Gradient Boosting 회귀 모델 평가 ===\n",
            "Mean Squared Error (MSE): 7.08\n",
            "R-squared (R²): 0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhgNQ8-SNKah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}